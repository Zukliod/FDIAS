import cv2
from ultralytics import YOLO

input_video_path = 'input/3.mp4'
output_video_path = 'output/3.avi'

model_person = YOLO("yolov8n.pt")
model_face = YOLO("yolov8n-face.pt")

cap = cv2.VideoCapture(input_video_path)

if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

out = cv2.VideoWriter(
    output_video_path,
    cv2.VideoWriter_fourcc(*'XVID'),
    fps,
    (frame_width, frame_height)
)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results_person = model_person.predict(source=frame, save=False, conf=0.5)
    results_face = model_face.predict(source=frame, save=False, conf=0.5)

    for result in results_person[0].boxes.data.tolist():
        x1, y1, x2, y2, confidence, class_id = result
        if int(class_id) == 0:
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(frame, f'Person: {confidence:.2f}', (int(x1), int(y1) - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    for result in results_face[0].boxes.data.tolist():
        x1, y1, x2, y2, confidence, class_id = result
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
        cv2.putText(frame, f'Face: {confidence:.2f}', (int(x1), int(y1) - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    out.write(frame)
    cv2.imshow('Human and Face Detection', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()

print(f"Output video saved to: {output_video_path}")
